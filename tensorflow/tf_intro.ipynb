{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Low-level-TensorFlow-API\" data-toc-modified-id=\"Low-level-TensorFlow-API-1\">Low-level TensorFlow API</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Graph\" data-toc-modified-id=\"Graph-1.1\">Graph</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Session\" data-toc-modified-id=\"Session-1.2\">Session</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Tensors\" data-toc-modified-id=\"Tensors-1.3\">Tensors</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Constants\" data-toc-modified-id=\"Constants-1.3.1\">Constants</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Variables\" data-toc-modified-id=\"Variables-1.3.2\">Variables</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Placeholders\" data-toc-modified-id=\"Placeholders-1.3.3\">Placeholders</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Training-a-model\" data-toc-modified-id=\"Training-a-model-1.4\">Training a model</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Higher-level-TensorFlow-API:-Estimators\" data-toc-modified-id=\"Higher-level-TensorFlow-API:-Estimators-2\">Higher-level TensorFlow API: Estimators</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#Custom-model\" data-toc-modified-id=\"Custom-model-3\">Custom model</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/PycharmProjects/Playfield/tensorflow_introduction.ipynb#References\" data-toc-modified-id=\"References-4\">References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level TensorFlow API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _graph_ is used to define operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call the default graph\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# print operations in the graph\n",
    "for op in graph.get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are run within a _session_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "2.3\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2.3)\n",
    "\n",
    "# run an operation without a session\n",
    "print(a)\n",
    "\n",
    "# run the operation within a session\n",
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The session could be used with automatic closing like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are data structures in which data is stored, similar to multi dimensional arrays in NumPy. One type of a tensor is _constant_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: Tensor(\"Const_1:0\", shape=(4,), dtype=int32)\n",
      "result: Tensor(\"Mul:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Define two constants\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "print(\"x1:\", x1)\n",
    "\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "print(\"result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensors above, the constants, or 'result', are just models. They aren't actually calculated. To print/access them, they need to be run in a session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 12 21 32]\n",
      "2.3\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(result))\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from 'constants' there are also 'placeholder' and 'variable' types of tensors. Variables are values that can change, just like in any programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var1:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "b = tf.Variable(2.0, name='var1')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables need to be initialised by explicitly calling a special operation. To initialise all variables you can use the following function, then access the variable 'b'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders are values (tensors) which are unassigned, and that will be initialized by the session when it's run. They usually represent external inputs. These are used for training data. The object that is fed to Placeholder is called feed_dict - a key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "p1 = tf.placeholder(\"float\")\n",
    "p2 = tf.placeholder(\"float\")\n",
    "y = tf.multiply(p1, p2)\n",
    "\n",
    "# create a feed_dict object\n",
    "feed_dict = {p1: 2, p2: 3}\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the sessions can be run on a GPU, CPU, a cluster etc., and you can choose where to run it. The complete picture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cv-tricks.com/wp-content/uploads/2017/02/xTensorflow_Graph_0.png.pagespeed.ic.U_RLEnluD2.webp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3])\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(linear_model, feed_dict={x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "\n",
    "# Create a summary for the loss value\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "# Merge all summaries and write them to file\n",
    "merged = tf.summary.merge_all()\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an optimizer. Optimizers slowly change each variable until a loss function is minimized. The simplest example of an optimizer in tf is gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Create a tf.summary.FileWriter object that takes a 'logdir' destination, and optinally the model's graph\n",
    "train_writer = tf.summary.FileWriter('./train', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go through 1000 iterations with the above learning rate of 0.01, and print out the learned variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.84079814], dtype=float32), array([ 0.53192717], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAF3CAYAAABpFHt+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACyAqEFAABkBUILAADICoQWAACQFf5/xKwIlN2HuQ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fcb4cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.run(init)\n",
    "loss_plot = []\n",
    "for i in range(100):\n",
    "    sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    loss_plot.append(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n",
    "    \n",
    "    # Record summaries\n",
    "    summary = sess.run(merged, feed_dict={x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    train_writer.add_summary(summary, i)\n",
    "    \n",
    "#     print(\"W: %2f, b: %.2f\" % (sess.run(W), sess.run(b)))\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(np.linspace(start=1, stop=100, num=100), loss_plot)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss function\")\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-level TensorFlow API: Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators enable a more high-level and easier workflow with TensorFlow, simplifying: training, evaluation and dataset management. The above linear regression example is much simpler using Estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmplclskeii\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmplclskeii', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmplclskeii/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 915.919\n",
      "INFO:tensorflow:loss = 0.364415, step = 101 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 859.698\n",
      "INFO:tensorflow:loss = 0.0207924, step = 201 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.576\n",
      "INFO:tensorflow:loss = 0.00793199, step = 301 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 851.1\n",
      "INFO:tensorflow:loss = 0.00313569, step = 401 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.118\n",
      "INFO:tensorflow:loss = 0.00027045, step = 501 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.6\n",
      "INFO:tensorflow:loss = 5.94418e-05, step = 601 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.313\n",
      "INFO:tensorflow:loss = 4.91261e-06, step = 701 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.241\n",
      "INFO:tensorflow:loss = 1.51277e-06, step = 801 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.502\n",
      "INFO:tensorflow:loss = 3.61535e-07, step = 901 (0.183 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmplclskeii/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.5374e-08.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-26-14:09:12\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmplclskeii/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-26-14:09:14\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.7464e-08, global_step = 1000, loss = 6.98558e-08\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-26-14:09:15\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmplclskeii/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-26-14:09:16\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00253613, global_step = 1000, loss = 0.0101445\n",
      "train metrics: {'average_loss': 1.7463956e-08, 'loss': 6.9855822e-08, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025361348, 'loss': 0.010144539, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# A list of features\n",
    "feature_cols = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# Use LinearRegressor Estimator. There are various types of Estimators in tf, for classification, regression, neural nets etc.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_cols)\n",
    "\n",
    "# Generate the training and evaluation (testing) data\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "\n",
    "# Input training and evaluation data into the estimator, specifying batch size and number of epochs\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": x_train}, y=y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "       \n",
    "# Train the model in 1000 training steps\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Evaluate the model\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\" % train_metrics)\n",
    "print(\"eval metrics: %r\" % eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow enables to build custom models, that is, to create a model which is not included in tf.estimator using low-level tf API, while still being able to use the benefits of high-level estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmpdx053qlu\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmpdx053qlu', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmpdx053qlu/model.ckpt.\n",
      "INFO:tensorflow:loss = 19.4683979238, step = 1\n",
      "INFO:tensorflow:global_step/sec: 920.546\n",
      "INFO:tensorflow:loss = 0.024501608079, step = 101 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 848.702\n",
      "INFO:tensorflow:loss = 0.00295356546819, step = 201 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.032\n",
      "INFO:tensorflow:loss = 7.99642422051e-05, step = 301 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.149\n",
      "INFO:tensorflow:loss = 1.25875577107e-05, step = 401 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.102\n",
      "INFO:tensorflow:loss = 2.90791186561e-06, step = 501 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.599\n",
      "INFO:tensorflow:loss = 7.63771601098e-08, step = 601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.276\n",
      "INFO:tensorflow:loss = 1.65456004275e-08, step = 701 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.194\n",
      "INFO:tensorflow:loss = 3.10647469094e-09, step = 801 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.841\n",
      "INFO:tensorflow:loss = 1.47153317012e-10, step = 901 (0.166 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmpdx053qlu/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.40078250442e-11.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-26-14:09:23\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmpdx053qlu/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-26-14:09:24\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.29762e-11\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-26-14:09:24\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/kt/50kqr6596n52pkfjk2x5hl3h0000gp/T/tmpdx053qlu/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-26-14:09:26\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101004\n",
      "train metrics: {'loss': 1.2976225e-11, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100369, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Create the new model which returns tf.estimator.EstimatorSpec\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Similar to the low-level API, define the variables that need to be estimated,\n",
    "    # and the graph producing the output\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W * features['x'] + b\n",
    "    \n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    \n",
    "    # Training sub-graph. Why do we need to change the global step?\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss), tf.assign_add(global_step, 1))\n",
    "    \n",
    "    # Use EstimatorSpec to connect sub-graphs\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=y, loss=loss, train_op=train)\n",
    "\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "\n",
    "# The rest is same as earlier:\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a similar (slightly better) result with our custom model, minimizing the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv-tricks.com website (link: http://cv-tricks.com/artificial-intelligence/deep-learning/deep-learning-frameworks/tensorflow/tensorflow-tutorial/)\n",
    "- tensorflow.org website"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
